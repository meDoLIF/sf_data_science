{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meDoLIF/sf_data_science/blob/main/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbflOu-A_xFU",
        "outputId": "e9fbfcd3-baa7-4691-d3c4-f1ddc8c7695c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "q:\\DS\\python\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#импорт библиотек\n",
        "import numpy as np #для матричных вычислений\n",
        "import pandas as pd #для анализа и предобработки данных\n",
        "import matplotlib.pyplot as plt #для визуализации\n",
        "import seaborn as sns #для визуализации\n",
        "\n",
        "from sklearn import linear_model #линейные моделиё\n",
        "from sklearn import tree #деревья решений\n",
        "from sklearn import ensemble #ансамбли\n",
        "from sklearn import metrics #метрики\n",
        "from sklearn import preprocessing #предобработка\n",
        "from sklearn.model_selection import train_test_split #сплитование выборки\n",
        "from sklearn.model_selection import cross_val_score #Кросс валидация\n",
        "\n",
        "# Импорт оптимизаторов параметров\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "import hyperopt\n",
        "from hyperopt import hp, fmin, tpe, Trials\n",
        "\n",
        "import optuna\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sul8SmCl_xFa"
      },
      "source": [
        "Необходимо обучить две модели: логистическую регрессию и случайный лес. Далее нужно сделать подбор гиперпараметров с помощью базовых и продвинутых методов оптимизации. Важно использовать все четыре метода (GridSeachCV, RandomizedSearchCV, Hyperopt, Optuna) хотя бы по разу, максимальное количество итераций не должно превышать 50.\n",
        "\n",
        "В качестве метрики будем использовать F1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsu7Kq7R_xFc"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/_train_sem09 (1).csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_t8c79p_xFd",
        "outputId": "816fdebb-7ff2-49e3-803b-89a1c84b4949"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Activity</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>D1767</th>\n",
              "      <th>D1768</th>\n",
              "      <th>D1769</th>\n",
              "      <th>D1770</th>\n",
              "      <th>D1771</th>\n",
              "      <th>D1772</th>\n",
              "      <th>D1773</th>\n",
              "      <th>D1774</th>\n",
              "      <th>D1775</th>\n",
              "      <th>D1776</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.497009</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.132956</td>\n",
              "      <td>0.678031</td>\n",
              "      <td>0.273166</td>\n",
              "      <td>0.585445</td>\n",
              "      <td>0.743663</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.606291</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111209</td>\n",
              "      <td>0.803455</td>\n",
              "      <td>0.106105</td>\n",
              "      <td>0.411754</td>\n",
              "      <td>0.836582</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.033300</td>\n",
              "      <td>0.480124</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.209791</td>\n",
              "      <td>0.610350</td>\n",
              "      <td>0.356453</td>\n",
              "      <td>0.517720</td>\n",
              "      <td>0.679051</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.538825</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.196344</td>\n",
              "      <td>0.724230</td>\n",
              "      <td>0.235606</td>\n",
              "      <td>0.288764</td>\n",
              "      <td>0.805110</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.517794</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.494734</td>\n",
              "      <td>0.781422</td>\n",
              "      <td>0.154361</td>\n",
              "      <td>0.303809</td>\n",
              "      <td>0.812646</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1777 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
              "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
              "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
              "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
              "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
              "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
              "\n",
              "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
              "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
              "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
              "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
              "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
              "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
              "\n",
              "   D1774  D1775  D1776  \n",
              "0      0      0      0  \n",
              "1      0      1      0  \n",
              "2      0      0      0  \n",
              "3      0      0      0  \n",
              "4      0      0      0  \n",
              "\n",
              "[5 rows x 1777 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#проверим что датасет сформировался корректно\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2fsD16z_xFe"
      },
      "source": [
        "* Первый столбец Activity содержит экспериментальные данные, описывающие фактический биологический ответ [0, 1]; (Целевой признак)\n",
        "* Остальные столбцы D1-D1776 представляют собой молекулярные дескрипторы — это вычисляемые свойства, которые могут фиксировать некоторые характеристики молекулы, например размер, форму или состав элементов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gupgfl3Q_xFe",
        "outputId": "301f14c5-88e9-4523-9a67-8cd6ea3a038c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер df (3751, 1777)\n",
            "Размер X (3751, 1776)\n",
            "Размер y (3751,)\n"
          ]
        }
      ],
      "source": [
        "# Разобъём наши данные на Зависимые (y) и Независимые (X)\n",
        "\n",
        "X = df.drop(['Activity'], axis = 1)\n",
        "y = df['Activity']\n",
        "\n",
        "#Проверим по размерам выборок что разделение прошло успешно\n",
        "\n",
        "print('Размер df', df.shape)\n",
        "print('Размер X', X.shape)\n",
        "print('Размер y', y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBz-aBgX_xFf",
        "outputId": "3ceadd62-18a4-42a0-9038-bcaeec010475"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    0.542255\n",
              "0    0.457745\n",
              "Name: Activity, dtype: float64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Проверим, насколько равномерно разделены целевые данные, чтобы определить необходимость в стратификации при разделении на тренировочную и тестовую выборки\n",
        "\n",
        "y.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StlLWjLs_xFg"
      },
      "source": [
        "Данные разделены примерно поровну, поэтому делать стратификацию не обязательно"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFlmRB9p_xFh"
      },
      "outputs": [],
      "source": [
        "#Разделим данные на тренировочные и тестовые\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ped5v9h_xFh"
      },
      "source": [
        "# Создание BaseLine моделей\n",
        "\n",
        "Высчитаем F1-score для моделей Логистической регрессии и Случайном лесе на параметрах по умолчанию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYHuHcSX_xFi",
        "outputId": "a86d91d5-96e6-43f3-9a4e-6aa4c3239206"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "#Baseline для логистической регрессии\n",
        "logReg_base = linear_model.LogisticRegression(random_state=42, max_iter= 50)\n",
        "\n",
        "logReg_base.fit(X_train, y_train)\n",
        "\n",
        "y_pred_logReg_base = logReg_base.predict(X_test)\n",
        "\n",
        "f1_logReg_base = metrics.f1_score(y_test, y_pred_logReg_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW_OwExf_xFj",
        "outputId": "8baa88ab-9ac8-44ea-ac3d-0d445c9a57e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для логистической регресии равен 0.79\n"
          ]
        }
      ],
      "source": [
        "print('F1-score на Baseline для логистической регресии равен {:.2f}'.format(f1_logReg_base))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_Iem5oZ_xFj"
      },
      "outputs": [],
      "source": [
        "#Baseline для случайного леса\n",
        "\n",
        "rf_base = ensemble.RandomForestClassifier(random_state= 42)\n",
        "\n",
        "rf_base.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf_base = rf_base.predict(X_test)\n",
        "\n",
        "f1_rf_base = metrics.f1_score(y_test, y_pred_rf_base)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1--UVvIt_xFk",
        "outputId": "24850df6-5bbf-442e-f7a6-4ea26d82630f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для случайного леса равен 0.83\n"
          ]
        }
      ],
      "source": [
        "print('F1-score на Baseline для случайного леса равен {:.2f}'.format(f1_rf_base))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcBHVU3K_xFl"
      },
      "source": [
        "# Построение модели с помощью GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JNe-8_g_xFl"
      },
      "source": [
        "## На основе логистической регресии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAeHlg9g_xFl",
        "outputId": "c9e6bf11-3227-4478-8fcd-adcce7a96d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 12.1 s\n",
            "Wall time: 6min 27s\n"
          ]
        }
      ],
      "source": [
        "param_grid = [\n",
        "    {'penalty' : ['l2', 'none'], # тип регуляризации\n",
        "    'solver' : ['newton-cg', 'lbfgs', 'sag'], # алгоритм оптимизации\n",
        "    'C' : [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}, # уровень силы регурялизации\n",
        "    #поскольку разные алгоритмы поддерживают разные типы регуляризации мы создадим еще 1 набор параметров\n",
        "    \n",
        "    {'penalty': ['l1', 'l2'] ,\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}\n",
        "]\n",
        "\n",
        "gs_logReg = GridSearchCV(\n",
        "    estimator = linear_model.LogisticRegression(random_state= 42, max_iter = 50),\n",
        "    param_grid = param_grid,\n",
        "    cv = 5,\n",
        "    n_jobs = -1,\n",
        "    scoring='f1'\n",
        ")\n",
        "\n",
        "%time gs_logReg.fit(X_train, y_train)\n",
        "\n",
        "y_pred_gs_logReg = gs_logReg.predict(X_test)\n",
        "\n",
        "f1_gs_logReg = metrics.f1_score(y_test, y_pred_gs_logReg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYKbHTyJ_xFm",
        "outputId": "1587257a-547e-4286-f2ab-e840ad425a74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Наилучшие значения гиперпараметров: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
          ]
        }
      ],
      "source": [
        "print(\"Наилучшие значения гиперпараметров: {}\".format(gs_logReg.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60SwOY4I_xFm",
        "outputId": "1f359047-9c49-465b-bdbe-c62ed04dbd03"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# отрисуем, как менялась точность при различных гиперпараметрах\n",
        "visual = pd.pivot_table(pd.DataFrame(gs_logReg.cv_results_),\n",
        "                        values='mean_test_score', index='param_C',\n",
        "                        columns='param_solver')\n",
        "sns.heatmap(visual)\n",
        "plt.title('Тепловая карта зависимости метрики accuracy от solver и С') # подпись графика\n",
        "sns.set(rc={'figure.figsize':(12, 8)}) #задаем размер графика"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-X1Ug-E_xFn"
      },
      "source": [
        "Из тепловой карты видно, что нет смысла пробовать создать модель с большей силой регуляризации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ixz2fbmC_xFn",
        "outputId": "9423dad7-7099-44d3-e727-4c88da92e7ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для логистической регресии равен 0.79\n",
            "F1-score на GridSearchCV для логистической регресии равен 0.79\n"
          ]
        }
      ],
      "source": [
        "#Сравним результат с BaseLine\n",
        "print('F1-score на Baseline для логистической регресии равен {:.2f}'.format(f1_logReg_base))\n",
        "print('F1-score на GridSearchCV для логистической регресии равен {:.2f}'.format(f1_gs_logReg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5FHr5BV_xFn"
      },
      "source": [
        "К сожалению получить показатель лучше чем BaseLine не удалось"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OjWGXLa_xFo"
      },
      "source": [
        "## На основе Случайного Леса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5Yk2mGB_xFo",
        "outputId": "be51c34f-9881-4d6d-818e-eeedf038a796"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 34.3 s\n",
            "Wall time: 21min 47s\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'min_samples_leaf' : list(np.linspace(5, 25, 10, dtype=int)),\n",
        "    'max_depth' : list(np.linspace(1, 30, 6, dtype = int)),\n",
        "    'n_estimators' : list(np.linspace(80,200, 30, dtype = int))\n",
        "}\n",
        "\n",
        "gs_rf = GridSearchCV(\n",
        "    estimator= ensemble.RandomForestClassifier(random_state= 42),\n",
        "    param_grid= param_grid,\n",
        "    cv = 5,\n",
        "    n_jobs= -1,\n",
        "    scoring = 'f1'\n",
        ")\n",
        "\n",
        "%time gs_rf.fit(X_train, y_train)\n",
        "\n",
        "f1_gs_rf = gs_rf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZFI64BO_xFo",
        "outputId": "4edb1047-3397-44a4-e148-d55853bd2345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Наилучшие значения гиперпараметров: {'max_depth': 30, 'min_samples_leaf': 5, 'n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "print(\"Наилучшие значения гиперпараметров: {}\".format(gs_rf.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RefXHEki_xFp",
        "outputId": "ec6363ff-3599-49fb-e7c1-816dc824fc5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для случайного леса равен 0.83\n",
            "F1-score на GridResearchCV для случайного леса равен 0.83\n"
          ]
        }
      ],
      "source": [
        "print('F1-score на Baseline для случайного леса равен {:.2f}'.format(f1_rf_base))\n",
        "print('F1-score на GridResearchCV для случайного леса равен {:.2f}'.format(f1_gs_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QnoypJ7_xFp"
      },
      "source": [
        "К сожалению получить показатель лучше чем BaseLine не удалось"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrQA3Zyy_xFp"
      },
      "source": [
        "# RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YDvSL3S_xFp"
      },
      "source": [
        "## Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8PVkVxW_xFp",
        "outputId": "8482506c-5ca8-46a6-8425-300392744bd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 10.7 s\n",
            "Wall time: 5min 41s\n"
          ]
        }
      ],
      "source": [
        "param_distribution = [\n",
        "    {'penalty' : ['l2', 'none'], # тип регуляризации\n",
        "    'solver' : ['newton-cg', 'lbfgs', 'sag'], # алгоритм оптимизации\n",
        "    'C' : [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}, # уровень силы регурялизации\n",
        "    #поскольку разные алгоритмы поддерживают разные типы регуляризации мы создадим еще 1 набор параметров\n",
        "    \n",
        "    {'penalty': ['l1', 'l2'] ,\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}\n",
        "]\n",
        "\n",
        "rs_logReg = RandomizedSearchCV(\n",
        "    estimator= linear_model.LogisticRegression(random_state=42, max_iter=50),\n",
        "    param_distributions=param_distribution,\n",
        "    cv = 5,\n",
        "    n_iter= 50,\n",
        "    n_jobs= -1,\n",
        "    scoring='f1'\n",
        ")\n",
        "\n",
        "%time rs_logReg.fit(X_train, y_train)\n",
        "\n",
        "f1_rs_logReg = rs_logReg.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujd3sFU9_xFq",
        "outputId": "7bd2095a-6d9e-4ba7-a070-d645fd446272"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Наилучшие значения гиперпараметров: {'solver': 'newton-cg', 'penalty': 'l2', 'C': 0.1}\n"
          ]
        }
      ],
      "source": [
        "print(\"Наилучшие значения гиперпараметров: {}\".format(rs_logReg.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwZVYyeG_xFq",
        "outputId": "53b58d96-e3a5-49e8-bfd4-ef45c8e04e29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для логистической регресии равен 0.79\n",
            "F1-score на RandomizedSrearchCV для логистической регресии равен 0.79\n"
          ]
        }
      ],
      "source": [
        "#Сравним результат с BaseLine\n",
        "print('F1-score на Baseline для логистической регресии равен {:.2f}'.format(f1_logReg_base))\n",
        "print('F1-score на RandomizedSrearchCV для логистической регресии равен {:.2f}'.format(f1_rs_logReg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxnZ4dHs_xFq"
      },
      "source": [
        "## Случайный лес"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ9kFYxK_xFq"
      },
      "outputs": [],
      "source": [
        "param_distribution = {\n",
        "    'min_samples_leaf' : list(np.linspace(5, 25, 10, dtype=int)),\n",
        "    'max_depth' : list(np.linspace(1, 30, 6, dtype = int)),\n",
        "    'n_estimators' : list(np.linspace(80,200, 30, dtype = int))\n",
        "}\n",
        "\n",
        "rs_rf = RandomizedSearchCV(\n",
        "    estimator=ensemble.RandomForestClassifier(random_state=42),\n",
        "    param_distributions=param_distribution,\n",
        "    cv = 5,\n",
        "    n_iter = 50,\n",
        "    n_jobs= -1,\n",
        "    scoring= 'f1'\n",
        ")\n",
        "\n",
        "rs_rf.fit(X_train, y_train)\n",
        "\n",
        "f1_rs_rf = rs_rf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOR_wZDo_xFr",
        "outputId": "0b5288af-19f0-497c-85f0-89c1eb27f5cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Наилучшие значения гиперпараметров: {'n_estimators': 125, 'min_samples_leaf': 5, 'max_depth': 24}\n"
          ]
        }
      ],
      "source": [
        "print(\"Наилучшие значения гиперпараметров: {}\".format(rs_rf.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzDCgdLf_xFr",
        "outputId": "52189173-dbbf-4cfe-9ebf-c09684b827f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для случайного леса равен 0.83\n",
            "F1-score на RandomizedSrearchCV для случайного леса равен 0.83\n"
          ]
        }
      ],
      "source": [
        "#Сравним результат с BaseLine\n",
        "print('F1-score на Baseline для случайного леса равен {:.2f}'.format(f1_rf_base))\n",
        "print('F1-score на RandomizedSrearchCV для случайного леса равен {:.2f}'.format(f1_rs_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo56AwTS_xFr"
      },
      "source": [
        "# HyperOpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsSGHH0Q_xFr"
      },
      "source": [
        "## Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDkZ11dL_xFs",
        "outputId": "f76c08b8-4ddf-4153-e634-dc933ca947d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"{'penalty': hp.choice(label='penalty', options= ['l1', 'l2']) ,\\n    'solver': hp.choice(label = 'solver', options= ['liblinear', 'saga']),\\n    'C': hp.loguniform('C', low = -2*np.log(10), high = 1)}\""
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#зададим пространство поиска гиперпараметров\n",
        "\"\"\"space = [\n",
        "    {'penalty' : hp.choice(label='penalty', options= ['l2', 'none']), # тип регуляризации\n",
        "    'solver' : hp.choice(label = 'solver', options= ['newton-cg', 'lbfgs', 'sag']), # алгоритм оптимизации\n",
        "    'C' : hp.loguniform('C', low = -2*np.log(10), high = 1)}, # уровень силы регурялизации\n",
        "    #поскольку разные алгоритмы поддерживают разные типы регуляризации мы создадим еще 1 набор параметров\n",
        "    \n",
        "    {'penalty': hp.choice(label='penalty', options= ['l1', 'l2']) ,\n",
        "    'solver': hp.choice(label = 'solver', options= ['liblinear', 'saga']),\n",
        "    'C': hp.loguniform('C', low = -2*np.log(10), high = 1)}\n",
        "]\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTk_Por6_xFs"
      },
      "outputs": [],
      "source": [
        "space ={\n",
        "    'penalty' : hp.choice(label='penalty', options= ['l2', 'none']), # тип регуляризации\n",
        "    'solver' : hp.choice(label = 'solver', options= ['newton-cg', 'lbfgs', 'sag']), # алгоритм оптимизации\n",
        "    'C' : hp.loguniform(label='C', low=-2*np.log(10), high=2*np.log(10))}, # уровень силы регурялизации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xK-PbkBk_xFs"
      },
      "outputs": [],
      "source": [
        "random_state = 42\n",
        "\n",
        "def hyperopt_lr(params, cv = 5, X = X_train, y = y_train, random_state = random_state):\n",
        "    params = {\n",
        "        'penalty' : hp.choice(label='penalty', options= ['l2', 'none']), # тип регуляризации\n",
        "        'solver' : hp.choice(label = 'solver', options= ['newton-cg', 'lbfgs', 'sag']), # алгоритм оптимизации\n",
        "        'C' : hp.loguniform(label='C', low=-2*np.log(10), high=2*np.log(10))\n",
        "    }\n",
        "    \n",
        "    model = linear_model.LogisticRegression(**params, random_state = random_state)\n",
        "    \n",
        "    model.fit(X, y)\n",
        "    \n",
        "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
        "    \n",
        "    return -score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1sCS-n3_xFt",
        "outputId": "43b28f8a-80bd-46d8-ed18-d1b9d90b6a06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "TPE is being used as the default algorithm.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 0 ns\n",
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "job exception: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got 0 switch\n",
            "1   hyperopt_param\n",
            "2     Literal{solver}\n",
            "3     randint\n",
            "4       Literal{3}\n",
            "5   Literal{newton-cg}\n",
            "6   Literal{lbfgs}\n",
            "7   Literal{sag}.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got 0 switch\n1   hyperopt_param\n2     Literal{solver}\n3     randint\n4       Literal{3}\n5   Literal{newton-cg}\n6   Literal{lbfgs}\n7   Literal{sag}.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mq:\\DS\\Projects\\sf_data_science\\Trainig\\ML-7. Оптимизация гиперпараметров модели\\Miniproject.ipynb Cell 42\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m trials \u001b[39m=\u001b[39m Trials()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m best \u001b[39m=\u001b[39m fmin(hyperopt_lr, \u001b[39m#наша функция\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     space \u001b[39m=\u001b[39;49m space, \u001b[39m#Пространство параметров\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     max_evals\u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m, \u001b[39m#Количество итераций\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     trials \u001b[39m=\u001b[39;49m trials,\u001b[39m# логирование результатов\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     rstate \u001b[39m=\u001b[39;49m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mdefault_rng(random_state)\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mНаилучшие параметры \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(best))\n",
            "File \u001b[1;32mq:\\DS\\python\\lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[39m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[39mif\u001b[39;00m allow_trials_fmin \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(trials, \u001b[39m\"\u001b[39m\u001b[39mfmin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[39mreturn\u001b[39;00m trials\u001b[39m.\u001b[39;49mfmin(\n\u001b[0;32m    541\u001b[0m         fn,\n\u001b[0;32m    542\u001b[0m         space,\n\u001b[0;32m    543\u001b[0m         algo\u001b[39m=\u001b[39;49malgo,\n\u001b[0;32m    544\u001b[0m         max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[0;32m    545\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    546\u001b[0m         loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[0;32m    547\u001b[0m         max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[0;32m    548\u001b[0m         rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[0;32m    549\u001b[0m         pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[0;32m    550\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    551\u001b[0m         catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[0;32m    552\u001b[0m         return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[0;32m    553\u001b[0m         show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[0;32m    554\u001b[0m         early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[0;32m    555\u001b[0m         trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[0;32m    556\u001b[0m     )\n\u001b[0;32m    558\u001b[0m \u001b[39mif\u001b[39;00m trials \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(trials_save_file):\n",
            "File \u001b[1;32mq:\\DS\\python\\lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[39m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[39m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[39m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfmin\u001b[39;00m \u001b[39mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[39mreturn\u001b[39;00m fmin(\n\u001b[0;32m    672\u001b[0m     fn,\n\u001b[0;32m    673\u001b[0m     space,\n\u001b[0;32m    674\u001b[0m     algo\u001b[39m=\u001b[39;49malgo,\n\u001b[0;32m    675\u001b[0m     max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[0;32m    676\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    677\u001b[0m     loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[0;32m    678\u001b[0m     trials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    679\u001b[0m     rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[0;32m    680\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    681\u001b[0m     max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[0;32m    682\u001b[0m     allow_trials_fmin\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# -- prevent recursion\u001b[39;49;00m\n\u001b[0;32m    683\u001b[0m     pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[0;32m    684\u001b[0m     catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[0;32m    685\u001b[0m     return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[0;32m    686\u001b[0m     show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[0;32m    687\u001b[0m     early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[0;32m    688\u001b[0m     trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[0;32m    689\u001b[0m )\n",
            "File \u001b[1;32mq:\\DS\\python\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[0;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[1;32mq:\\DS\\python\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[0;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[1;32mq:\\DS\\python\\lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[0;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
            "File \u001b[1;32mq:\\DS\\python\\lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[0;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
            "File \u001b[1;32mq:\\DS\\python\\lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[0;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
            "\u001b[1;32mq:\\DS\\Projects\\sf_data_science\\Trainig\\ML-7. Оптимизация гиперпараметров модели\\Miniproject.ipynb Cell 42\u001b[0m in \u001b[0;36mhyperopt_lr\u001b[1;34m(params, cv, X, y, random_state)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mpenalty\u001b[39m\u001b[39m'\u001b[39m : hp\u001b[39m.\u001b[39mchoice(label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpenalty\u001b[39m\u001b[39m'\u001b[39m, options\u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39m# тип регуляризации\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39msolver\u001b[39m\u001b[39m'\u001b[39m : hp\u001b[39m.\u001b[39mchoice(label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msolver\u001b[39m\u001b[39m'\u001b[39m, options\u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msag\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39m# алгоритм оптимизации\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m : hp\u001b[39m.\u001b[39mloguniform(label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m, low\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mlog(\u001b[39m10\u001b[39m), high\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mlog(\u001b[39m10\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m }\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model \u001b[39m=\u001b[39m linear_model\u001b[39m.\u001b[39mLogisticRegression(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams, random_state \u001b[39m=\u001b[39m random_state)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m score \u001b[39m=\u001b[39m cross_val_score(model, X, y, cv\u001b[39m=\u001b[39mcv, scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m\"\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mmean()\n\u001b[0;32m     <a href='vscode-notebook-cell:/q%3A/DS/Projects/sf_data_science/Trainig/ML-7.%20%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8/Miniproject.ipynb#Y100sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mscore\n",
            "File \u001b[1;32mq:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1091\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1063\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[39m    Fit the model according to the given training data.\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[39m    The SAGA solver supports both float64 and float32 bit arrays.\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1091\u001b[0m     solver \u001b[39m=\u001b[39m _check_solver(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msolver, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpenalty, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdual)\n\u001b[0;32m   1093\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC, numbers\u001b[39m.\u001b[39mNumber) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1094\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPenalty term must be positive; got (C=\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC)\n",
            "File \u001b[1;32mq:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:48\u001b[0m, in \u001b[0;36m_check_solver\u001b[1;34m(solver, penalty, dual)\u001b[0m\n\u001b[0;32m     46\u001b[0m all_solvers \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msag\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msaga\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     47\u001b[0m \u001b[39mif\u001b[39;00m solver \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m all_solvers:\n\u001b[1;32m---> 48\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     49\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLogistic Regression supports only solvers in \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     50\u001b[0m         \u001b[39m%\u001b[39m (all_solvers, solver)\n\u001b[0;32m     51\u001b[0m     )\n\u001b[0;32m     53\u001b[0m all_penalties \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39ml1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39melasticnet\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     54\u001b[0m \u001b[39mif\u001b[39;00m penalty \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m all_penalties:\n",
            "\u001b[1;31mValueError\u001b[0m: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got 0 switch\n1   hyperopt_param\n2     Literal{solver}\n3     randint\n4       Literal{3}\n5   Literal{newton-cg}\n6   Literal{lbfgs}\n7   Literal{sag}."
          ]
        }
      ],
      "source": [
        "%time\n",
        "\n",
        "trials = Trials()\n",
        "\n",
        "best = fmin(hyperopt_lr, #наша функция\n",
        "    space = space, #Пространство параметров\n",
        "    max_evals= 50, #Количество итераций\n",
        "    trials = trials,# логирование результатов\n",
        "    rstate = np.random.default_rng(random_state)\n",
        ")\n",
        "\n",
        "print('Наилучшие параметры {}'.format(best))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bBhtk7W_xFt"
      },
      "source": [
        "## Случайный лес"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEwBxS-S_xFt"
      },
      "outputs": [],
      "source": [
        "space={'n_estimators': hp.quniform('n_estimators', 80, 200, 1),\n",
        "       'max_depth' : hp.quniform('max_depth', 1, 30, 1),\n",
        "       'min_samples_leaf': hp.quniform('min_samples_leaf', 5, 25, 1)\n",
        "      }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWFFKevh_xFt"
      },
      "outputs": [],
      "source": [
        "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
        "    \n",
        "    params = {'n_estimators': int(params['n_estimators']), \n",
        "              'max_depth': int(params['max_depth']), \n",
        "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
        "    }\n",
        "    # используем эту комбинацию для построения модели   \n",
        "    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
        "\n",
        "    # обучаем модель\n",
        "    model.fit(X, y)\n",
        "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
        "    \n",
        "    return -score    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNg3sdKQ_xFt",
        "outputId": "e4667dbb-0a95-463a-d1d7-32c7924ffbb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 0 ns\n",
            "100%|██████████| 50/50 [02:08<00:00,  2.57s/trial, best loss: -0.8051423755259064]\n",
            "Наилучшие значения гиперпараметров {'max_depth': 28.0, 'min_samples_leaf': 5.0, 'n_estimators': 101.0}\n"
          ]
        }
      ],
      "source": [
        "%time\n",
        "\n",
        "trials = Trials() # используется для логирования результатов\n",
        "\n",
        "best=fmin(hyperopt_rf, # наша функция \n",
        "          space=space, # пространство гиперпараметров\n",
        "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
        "          max_evals=50, # максимальное количество итераций\n",
        "          trials=trials, # логирование результатов\n",
        "          rstate=np.random.default_rng(random_state)# фиксируем для повторяемости результата\n",
        "         )\n",
        "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IA4EXsKz_xFu"
      },
      "outputs": [],
      "source": [
        "# рассчитаем точность для тестовой выборки\n",
        "model = ensemble.RandomForestClassifier(\n",
        "    random_state=random_state, \n",
        "    n_estimators=int(best['n_estimators']),\n",
        "    max_depth=int(best['max_depth']),\n",
        "    min_samples_leaf=int(best['min_samples_leaf'])\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_ho_rf = model.predict(X_test)\n",
        "\n",
        "f1_ho_rf = metrics.f1_score(y_test, y_pred_ho_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oeFCuXm_xFu",
        "outputId": "80c0fd46-6a2b-464c-e6c0-e5d1ff16ea78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для случайного леса равен 0.83\n",
            "F1-score на HyperOpt для случайного леса равен 0.84\n"
          ]
        }
      ],
      "source": [
        "#Сравним результат с BaseLine\n",
        "print('F1-score на Baseline для случайного леса равен {:.2f}'.format(f1_rf_base))\n",
        "print('F1-score на HyperOpt для случайного леса равен {:.2f}'.format(f1_ho_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9NumOlY_xFu"
      },
      "source": [
        "# Optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYwn_FGd_xFu"
      },
      "source": [
        "## Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVxmchCk_xFu"
      },
      "outputs": [],
      "source": [
        "def optuna_lr(trial):\n",
        "    penalty = trial.suggest_categorical(name='penalty', choices= ['l2', 'none']) # тип регуляризации\n",
        "    solver = trial.suggest_categorical(name = 'solver', choices= ['newton-cg', 'lbfgs', 'sag']) # алгоритм оптимизации\n",
        "    C = trial.suggest_float(name='C', low=0.01, high=1, step = 0.1) # уровень силы регурялизации\n",
        "    \n",
        "    model = linear_model.LogisticRegression(\n",
        "        penalty = penalty,\n",
        "        solver = solver,\n",
        "        C = C,\n",
        "        random_state=random_state\n",
        "    )\n",
        "    \n",
        "    model.fit(X_train, y_train)\n",
        "    score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"f1\", n_jobs=-1).mean()\n",
        "    \n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4gL02Sg_xFv",
        "outputId": "afde146f-7d71-4935-99df-593385436b3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-06 22:12:04,945]\u001b[0m A new study created in memory with name: LogisticRegression\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\u001b[32m[I 2022-10-06 22:12:09,579]\u001b[0m Trial 0 finished with value: 0.7716759100571287 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.81}. Best is trial 0 with value: 0.7716759100571287.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:12:17,914]\u001b[0m Trial 1 finished with value: 0.7706757200427254 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.81}. Best is trial 0 with value: 0.7716759100571287.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\u001b[32m[I 2022-10-06 22:12:20,374]\u001b[0m Trial 2 finished with value: 0.7716759100571287 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.81}. Best is trial 0 with value: 0.7716759100571287.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:12:27,932]\u001b[0m Trial 3 finished with value: 0.7727369523832007 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.51}. Best is trial 3 with value: 0.7727369523832007.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\u001b[32m[I 2022-10-06 22:12:30,104]\u001b[0m Trial 4 finished with value: 0.7777418955251229 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.41000000000000003}. Best is trial 4 with value: 0.7777418955251229.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:12:37,553]\u001b[0m Trial 5 finished with value: 0.7690080349374169 and parameters: {'penalty': 'none', 'solver': 'sag', 'C': 0.01}. Best is trial 4 with value: 0.7777418955251229.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:12:44,019]\u001b[0m Trial 6 finished with value: 0.7794872072632637 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.31000000000000005}. Best is trial 6 with value: 0.7794872072632637.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
            "  warnings.warn(\"Line Search failed\")\n",
            "\u001b[32m[I 2022-10-06 22:13:32,753]\u001b[0m Trial 7 finished with value: 0.7233491452286801 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'C': 0.31000000000000005}. Best is trial 6 with value: 0.7794872072632637.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
            "  warnings.warn(\"Line Search failed\")\n",
            "\u001b[32m[I 2022-10-06 22:14:22,316]\u001b[0m Trial 8 finished with value: 0.7233491452286801 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'C': 0.6100000000000001}. Best is trial 6 with value: 0.7794872072632637.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:14:29,750]\u001b[0m Trial 9 finished with value: 0.7690080349374169 and parameters: {'penalty': 'none', 'solver': 'sag', 'C': 0.01}. Best is trial 6 with value: 0.7794872072632637.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:14:35,689]\u001b[0m Trial 10 finished with value: 0.7803982420461868 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.21000000000000002}. Best is trial 10 with value: 0.7803982420461868.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:14:41,707]\u001b[0m Trial 11 finished with value: 0.7803982420461868 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.21000000000000002}. Best is trial 10 with value: 0.7803982420461868.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:14:47,909]\u001b[0m Trial 12 finished with value: 0.7803982420461868 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.21000000000000002}. Best is trial 10 with value: 0.7803982420461868.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:14:53,259]\u001b[0m Trial 13 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:14:58,618]\u001b[0m Trial 14 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:15:01,998]\u001b[0m Trial 15 finished with value: 0.7749459870866194 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.01}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:15:07,348]\u001b[0m Trial 16 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:15:12,703]\u001b[0m Trial 17 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:15:20,150]\u001b[0m Trial 18 finished with value: 0.7690080349374169 and parameters: {'penalty': 'none', 'solver': 'sag', 'C': 0.6100000000000001}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\u001b[32m[I 2022-10-06 22:15:22,283]\u001b[0m Trial 19 finished with value: 0.7777418955251229 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.41000000000000003}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:15:27,877]\u001b[0m Trial 20 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:15:33,303]\u001b[0m Trial 21 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:15:39,749]\u001b[0m Trial 22 finished with value: 0.7794872072632637 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.31000000000000005}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:15:45,190]\u001b[0m Trial 23 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:15:51,558]\u001b[0m Trial 24 finished with value: 0.7803982420461868 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.21000000000000002}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:15:55,285]\u001b[0m Trial 25 finished with value: 0.7749459870866194 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.01}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
            "  warnings.warn(\"Line Search failed\")\n",
            "\u001b[32m[I 2022-10-06 22:16:48,993]\u001b[0m Trial 26 finished with value: 0.7233491452286801 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:16:55,979]\u001b[0m Trial 27 finished with value: 0.7794872072632637 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.31000000000000005}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:17:04,058]\u001b[0m Trial 28 finished with value: 0.7805104493934761 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.21000000000000002}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\u001b[32m[I 2022-10-06 22:17:06,433]\u001b[0m Trial 29 finished with value: 0.769831467646992 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.91}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:17:07,976]\u001b[0m Trial 30 finished with value: 0.7749459870866194 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.01}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:17:13,617]\u001b[0m Trial 31 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:17:19,227]\u001b[0m Trial 32 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:17:25,461]\u001b[0m Trial 33 finished with value: 0.7803982420461868 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.21000000000000002}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:17:31,051]\u001b[0m Trial 34 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:17:38,871]\u001b[0m Trial 35 finished with value: 0.7772292673632061 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.41000000000000003}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:17:46,602]\u001b[0m Trial 36 finished with value: 0.7723095667770445 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.7100000000000001}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:17:48,223]\u001b[0m Trial 37 finished with value: 0.7749459870866194 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.01}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
            "  warnings.warn(\"Line Search failed\")\n",
            "\u001b[32m[I 2022-10-06 22:18:41,153]\u001b[0m Trial 38 finished with value: 0.7233491452286801 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'C': 0.31000000000000005}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:18:49,800]\u001b[0m Trial 39 finished with value: 0.7727369523832007 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.51}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:18:53,618]\u001b[0m Trial 40 finished with value: 0.7749459870866194 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.01}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:18:59,490]\u001b[0m Trial 41 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:19:05,411]\u001b[0m Trial 42 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:19:12,196]\u001b[0m Trial 43 finished with value: 0.7803982420461868 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.21000000000000002}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:19:18,508]\u001b[0m Trial 44 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:19:27,207]\u001b[0m Trial 45 finished with value: 0.7690080349374169 and parameters: {'penalty': 'none', 'solver': 'sag', 'C': 0.21000000000000002}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:19:30,940]\u001b[0m Trial 46 finished with value: 0.7749459870866194 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.01}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:19:37,128]\u001b[0m Trial 47 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-10-06 22:19:44,156]\u001b[0m Trial 48 finished with value: 0.7794872072632637 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.31000000000000005}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n",
            "q:\\DS\\python\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "q:\\DS\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\u001b[32m[I 2022-10-06 22:19:46,494]\u001b[0m Trial 49 finished with value: 0.7560783598917695 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.21000000000000002}. Best is trial 13 with value: 0.7837290544819175.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 10min 46s\n",
            "Wall time: 7min 41s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "study = optuna.create_study(study_name='LogisticRegression', direction='maximize')\n",
        "\n",
        "study.optimize(optuna_lr, n_trials= 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cPXdK2e_xFv"
      },
      "outputs": [],
      "source": [
        "model = linear_model.LogisticRegression(**study.best_params, random_state=random_state)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_optuna_lr = model.predict(X_test)\n",
        "\n",
        "f1_optuna_lr = metrics.f1_score(y_test, y_pred_optuna_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWmizvwV_xFv",
        "outputId": "3960f447-036f-4591-d9e1-6d9cefdb21d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для логистической регресии равен 0.79\n",
            "F1-score на Optuna для логистической регресии равен 0.79\n"
          ]
        }
      ],
      "source": [
        "#Сравним результат с BaseLine\n",
        "print('F1-score на Baseline для логистической регресии равен {:.2f}'.format(f1_logReg_base))\n",
        "print('F1-score на Optuna для логистической регресии равен {:.2f}'.format(f1_optuna_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxeA5oiY_xFv"
      },
      "source": [
        "## Случайный лес"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTftpAvL_xFv"
      },
      "outputs": [],
      "source": [
        "def optuna_rf(trial):\n",
        "    n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
        "    max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
        "    \n",
        "    model = ensemble.RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_leaf = min_samples_leaf,\n",
        "        random_state=random_state \n",
        "    )\n",
        "    \n",
        "    model.fit(X_train, y_train)\n",
        "    score = cross_val_score(model, X_train, y_train, cv = 5, scoring = 'f1', n_jobs= -1).mean()\n",
        "    \n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZrgvySO_xFw",
        "outputId": "f4d3e7c8-37f1-4dc6-a381-f86973945312"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-06 22:03:13,352]\u001b[0m A new study created in memory with name: RandomForestClassification\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:03:18,077]\u001b[0m Trial 0 finished with value: 0.7832854118874215 and parameters: {'n_estimators': 117, 'max_depth': 15, 'min_samples_leaf': 14}. Best is trial 0 with value: 0.7832854118874215.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:03:21,972]\u001b[0m Trial 1 finished with value: 0.7653299426870736 and parameters: {'n_estimators': 194, 'max_depth': 8, 'min_samples_leaf': 24}. Best is trial 0 with value: 0.7832854118874215.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:03:26,264]\u001b[0m Trial 2 finished with value: 0.7784149554705364 and parameters: {'n_estimators': 181, 'max_depth': 10, 'min_samples_leaf': 16}. Best is trial 0 with value: 0.7832854118874215.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:03:28,208]\u001b[0m Trial 3 finished with value: 0.7776012600834094 and parameters: {'n_estimators': 92, 'max_depth': 20, 'min_samples_leaf': 19}. Best is trial 0 with value: 0.7832854118874215.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:03:30,562]\u001b[0m Trial 4 finished with value: 0.7664444353711548 and parameters: {'n_estimators': 152, 'max_depth': 7, 'min_samples_leaf': 17}. Best is trial 0 with value: 0.7832854118874215.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:03:33,885]\u001b[0m Trial 5 finished with value: 0.7943267642824081 and parameters: {'n_estimators': 117, 'max_depth': 27, 'min_samples_leaf': 8}. Best is trial 5 with value: 0.7943267642824081.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:03:37,693]\u001b[0m Trial 6 finished with value: 0.7924517358918148 and parameters: {'n_estimators': 160, 'max_depth': 23, 'min_samples_leaf': 9}. Best is trial 5 with value: 0.7943267642824081.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:03:41,946]\u001b[0m Trial 7 finished with value: 0.7966744018210792 and parameters: {'n_estimators': 176, 'max_depth': 25, 'min_samples_leaf': 6}. Best is trial 7 with value: 0.7966744018210792.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:03:44,424]\u001b[0m Trial 8 finished with value: 0.7768349011791655 and parameters: {'n_estimators': 130, 'max_depth': 27, 'min_samples_leaf': 19}. Best is trial 7 with value: 0.7966744018210792.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:03:46,360]\u001b[0m Trial 9 finished with value: 0.733004497518509 and parameters: {'n_estimators': 186, 'max_depth': 4, 'min_samples_leaf': 25}. Best is trial 7 with value: 0.7966744018210792.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:03:50,256]\u001b[0m Trial 10 finished with value: 0.8018454282130827 and parameters: {'n_estimators': 165, 'max_depth': 17, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.8018454282130827.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:03:54,168]\u001b[0m Trial 11 finished with value: 0.8024795275136976 and parameters: {'n_estimators': 167, 'max_depth': 17, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:03:57,846]\u001b[0m Trial 12 finished with value: 0.7997908575918184 and parameters: {'n_estimators': 156, 'max_depth': 16, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:01,257]\u001b[0m Trial 13 finished with value: 0.7925373645132074 and parameters: {'n_estimators': 168, 'max_depth': 15, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:04,255]\u001b[0m Trial 14 finished with value: 0.7860287207370696 and parameters: {'n_estimators': 139, 'max_depth': 19, 'min_samples_leaf': 11}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:07,993]\u001b[0m Trial 15 finished with value: 0.7817212634774383 and parameters: {'n_estimators': 199, 'max_depth': 12, 'min_samples_leaf': 13}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:11,409]\u001b[0m Trial 16 finished with value: 0.7987797240525929 and parameters: {'n_estimators': 147, 'max_depth': 21, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:15,415]\u001b[0m Trial 17 finished with value: 0.8007318786917039 and parameters: {'n_estimators': 170, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:17,396]\u001b[0m Trial 18 finished with value: 0.7878050938209491 and parameters: {'n_estimators': 86, 'max_depth': 17, 'min_samples_leaf': 12}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:20,158]\u001b[0m Trial 19 finished with value: 0.7933051371976857 and parameters: {'n_estimators': 134, 'max_depth': 12, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:21,562]\u001b[0m Trial 20 finished with value: 0.7364489007877661 and parameters: {'n_estimators': 164, 'max_depth': 3, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:25,614]\u001b[0m Trial 21 finished with value: 0.8010878643296676 and parameters: {'n_estimators': 171, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:30,006]\u001b[0m Trial 22 finished with value: 0.80211929659534 and parameters: {'n_estimators': 187, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:34,171]\u001b[0m Trial 23 finished with value: 0.7993318701177792 and parameters: {'n_estimators': 189, 'max_depth': 23, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:37,959]\u001b[0m Trial 24 finished with value: 0.7983400778740214 and parameters: {'n_estimators': 180, 'max_depth': 12, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:42,114]\u001b[0m Trial 25 finished with value: 0.7907089915004288 and parameters: {'n_estimators': 199, 'max_depth': 19, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:42,989]\u001b[0m Trial 26 finished with value: 0.7089358222735402 and parameters: {'n_estimators': 147, 'max_depth': 1, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:47,216]\u001b[0m Trial 27 finished with value: 0.7990041612358493 and parameters: {'n_estimators': 185, 'max_depth': 22, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:50,223]\u001b[0m Trial 28 finished with value: 0.7762500990480055 and parameters: {'n_estimators': 175, 'max_depth': 26, 'min_samples_leaf': 22}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:52,825]\u001b[0m Trial 29 finished with value: 0.7822474842972693 and parameters: {'n_estimators': 124, 'max_depth': 14, 'min_samples_leaf': 13}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:54,943]\u001b[0m Trial 30 finished with value: 0.777393663100498 and parameters: {'n_estimators': 104, 'max_depth': 18, 'min_samples_leaf': 15}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:04:59,042]\u001b[0m Trial 31 finished with value: 0.8013610667172006 and parameters: {'n_estimators': 169, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:05:02,747]\u001b[0m Trial 32 finished with value: 0.7982220638934805 and parameters: {'n_estimators': 161, 'max_depth': 29, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:05:07,013]\u001b[0m Trial 33 finished with value: 0.7998495694574871 and parameters: {'n_estimators': 190, 'max_depth': 24, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:05:10,285]\u001b[0m Trial 34 finished with value: 0.7966248900302216 and parameters: {'n_estimators': 151, 'max_depth': 27, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:05:13,042]\u001b[0m Trial 35 finished with value: 0.7759140218283473 and parameters: {'n_estimators': 179, 'max_depth': 7, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:05:16,610]\u001b[0m Trial 36 finished with value: 0.7927993775516715 and parameters: {'n_estimators': 165, 'max_depth': 28, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:05:20,346]\u001b[0m Trial 37 finished with value: 0.7940997582033498 and parameters: {'n_estimators': 194, 'max_depth': 10, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:05:23,076]\u001b[0m Trial 38 finished with value: 0.7817633690503217 and parameters: {'n_estimators': 155, 'max_depth': 25, 'min_samples_leaf': 18}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:05:26,585]\u001b[0m Trial 39 finished with value: 0.7906212129986901 and parameters: {'n_estimators': 175, 'max_depth': 14, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:05:29,035]\u001b[0m Trial 40 finished with value: 0.776227738521029 and parameters: {'n_estimators': 143, 'max_depth': 21, 'min_samples_leaf': 22}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:05:33,275]\u001b[0m Trial 41 finished with value: 0.8018564801506501 and parameters: {'n_estimators': 172, 'max_depth': 29, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:05:37,216]\u001b[0m Trial 42 finished with value: 0.7984470827418687 and parameters: {'n_estimators': 183, 'max_depth': 29, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:05:40,838]\u001b[0m Trial 43 finished with value: 0.7962166509521353 and parameters: {'n_estimators': 157, 'max_depth': 28, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:05:44,892]\u001b[0m Trial 44 finished with value: 0.8015783379320599 and parameters: {'n_estimators': 171, 'max_depth': 25, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:05:48,866]\u001b[0m Trial 45 finished with value: 0.7997211741228071 and parameters: {'n_estimators': 175, 'max_depth': 25, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:05:52,391]\u001b[0m Trial 46 finished with value: 0.7980260040959697 and parameters: {'n_estimators': 163, 'max_depth': 27, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:05:56,642]\u001b[0m Trial 47 finished with value: 0.7978320906052028 and parameters: {'n_estimators': 183, 'max_depth': 23, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:06:00,664]\u001b[0m Trial 48 finished with value: 0.7958898308721597 and parameters: {'n_estimators': 190, 'max_depth': 19, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n",
            "\u001b[32m[I 2022-10-06 22:06:04,768]\u001b[0m Trial 49 finished with value: 0.8017065695485794 and parameters: {'n_estimators': 172, 'max_depth': 16, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.8024795275136976.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 1min 12s\n",
            "Wall time: 2min 51s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "study = optuna.create_study(study_name='RandomForestClassification', direction='maximize')\n",
        "\n",
        "study.optimize(optuna_rf, n_trials= 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z465a3Gd_xFw"
      },
      "outputs": [],
      "source": [
        "model = ensemble.RandomForestClassifier(**study.best_params, random_state=random_state)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_optuna_rf = model.predict(X_test)\n",
        "\n",
        "f1_optuna_rf = metrics.f1_score(y_test, y_pred_optuna_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_BBjghp_xFw",
        "outputId": "5b5361f9-098f-48a7-fd74-9899d2f063ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для Случайного леса равен 0.83\n",
            "F1-score на Optuna для Случайного леса равен 0.82\n"
          ]
        }
      ],
      "source": [
        "#Сравним результат с BaseLine\n",
        "print('F1-score на Baseline для Случайного леса равен {:.2f}'.format(f1_rf_base))\n",
        "print('F1-score на Optuna для Случайного леса равен {:.2f}'.format(f1_optuna_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brolr1Md_xFw"
      },
      "source": [
        "# Итоги"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFKhUoXV_xFx"
      },
      "source": [
        "## Линейная регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IStglraB_xFx",
        "outputId": "150cc9bc-4079-4ec4-d8a7-0485ac085240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для логистической регресии равен 0.79\n",
            "F1-score на GridSearchCV для логистической регресии равен 0.79\n",
            "F1-score на RandomizedSrearchCV для логистической регресии равен 0.79\n",
            "F1-score на Optuna для логистической регресии равен 0.79\n"
          ]
        }
      ],
      "source": [
        "print('F1-score на Baseline для логистической регресии равен {:.2f}'.format(f1_logReg_base))\n",
        "print('F1-score на GridSearchCV для логистической регресии равен {:.2f}'.format(f1_gs_logReg))\n",
        "print('F1-score на RandomizedSrearchCV для логистической регресии равен {:.2f}'.format(f1_rs_logReg))\n",
        "\n",
        "print('F1-score на Optuna для логистической регресии равен {:.2f}'.format(f1_optuna_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zWZZdrZ_xFx"
      },
      "source": [
        "## Случайный лес"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfsS-q8s_xFx",
        "outputId": "99435056-d7a1-4e4f-f75c-051a81bbcab6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для Случайного леса равен 0.83\n",
            "F1-score на GridResearchCV для случайного леса равен 0.83\n",
            "F1-score на RandomizedSrearchCV для случайного леса равен 0.83\n",
            "F1-score на HyperOpt для случайного леса равен 0.84\n",
            "F1-score на Optuna для Случайного леса равен 0.82\n"
          ]
        }
      ],
      "source": [
        "print('F1-score на Baseline для Случайного леса равен {:.2f}'.format(f1_rf_base))\n",
        "print('F1-score на GridResearchCV для случайного леса равен {:.2f}'.format(f1_gs_rf))\n",
        "print('F1-score на RandomizedSrearchCV для случайного леса равен {:.2f}'.format(f1_rs_rf))\n",
        "print('F1-score на HyperOpt для случайного леса равен {:.2f}'.format(f1_ho_rf))\n",
        "print('F1-score на Optuna для Случайного леса равен {:.2f}'.format(f1_optuna_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4WW9tub_xFy"
      },
      "source": [
        "Для логистической регрессии лучший результат f1_score = ... показал ..., а для Случайного леса лучший результат f1_score = 0.84 показал HyperOpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJzC8bKW_xFy"
      },
      "source": [
        "P.S. В моём личном рейтинге страданий:\n",
        "\n",
        "1 Место - HyperOpt, который никак не хотел вбирать в себя параметры логистической регресии\\\n",
        "2 Место - GridResearchCV, который на большой сетке параметров забрал у меня ноутбук на 2.5 часа и пришлось перенастраивать сетку\\\n",
        "3 Место - Optuna, которая, к сожалению, не преодолеть BaseLine, а я так в нее верил"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2b63674c9b7ae46880e5fbc616ce37f303920e93739d93769ff2cc4e880ab55f"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}